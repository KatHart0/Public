{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define the API endpoint and parameters. You need to replace the \n",
    "# API URL with your own here, and define which data it is you're interested in. \n",
    "# In this example, I'm interested in all documents from the UK Government published in 2015.\n",
    "\n",
    "api_url = \"https://api.example.com/data\"  # Replace with your API URL\n",
    "params = {\n",
    "    'Source Type': 'Government',  \n",
    "    'Country': 'UK'\n",
    "}\n",
    "# Replace with your actual parameters. \n",
    "# The term on the left tells the API which data you're interested in as we hold it \n",
    "# in our database, and the term on the right is your way of specifying the sub-set or \n",
    "# 'filtering' - in this case, government documents authored in the UK. \n",
    "# This would ordinarily be too large a set to request at once, \n",
    "# so we'd recommend that you add in further parameters to specify the year, \n",
    "# publication date or particular authors as an example. \n",
    "headers = {\n",
    "    'Authorization': 'Bearer YOUR_API_KEY'  # Replace with your actual API key\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Make the request to the API \n",
    "response = requests.get(api_url, headers=headers, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Check if the request is successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Assuming the API returns JSON data\n",
    "else:\n",
    "    print(f\"Failed to fetch data: {response.status_code}\") \n",
    "    # This tells you if the API has failed\n",
    "    data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Process and transform the data\n",
    "if data:\n",
    "    # Convert the JSON data to a pandas DataFrame\n",
    "    df = pd.json_normalize(data)  # `json_normalize` is useful for nested JSON\n",
    "\n",
    "    # Optionally, perform any additional transformations here\n",
    "    # e.g., renaming columns, filtering rows, etc.\n",
    "    # df = df.rename(columns={'old_name': 'new_name'})\n",
    "    # df = df[df['column_name'] > some_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Step 5: Save the DataFrame to a CSV file\n",
    "    df.to_csv('output.csv', index=False)\n",
    "    print(\"Data successfully saved to output.csv\")\n",
    "else:\n",
    "    print(\"No data to write to CSV\")\n",
    "\n",
    "  # Step 6: Load the CSV into Tableau. You can configure your filing system to periodically generate a new CSV to replace the previous version. Once the file-path to the CSV has been set up in your Tableau dashboard, it should update automatically as new csv files are generated."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
